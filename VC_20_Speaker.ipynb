{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "# % pylab inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob \n",
    "import librosa.display\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout \n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the files from our folder and creating a dataframe from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103-1240-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103-1240-0001.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103-1240-0002.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103-1240-0003.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103-1240-0004.flac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "0  103-1240-0000.flac\n",
       "1  103-1240-0001.flac\n",
       "2  103-1240-0002.flac\n",
       "3  103-1240-0003.flac\n",
       "4  103-1240-0004.flac"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list the files\n",
    "filelist = os.listdir('source') \n",
    "#read them into pandas\n",
    "df_male = pd.DataFrame(filelist)\n",
    "df_male.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the 1 label to the dataframe representing male\n",
    "# df_male['label']='1'\n",
    "# df_male.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the column name to file\n",
    "df_male = df_male.rename(columns={0:'file'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103-1240-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103-1240-0001.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103-1240-0002.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103-1240-0003.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103-1240-0004.flac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file\n",
       "0  103-1240-0000.flac\n",
       "1  103-1240-0001.flac\n",
       "2  103-1240-0002.flac\n",
       "3  103-1240-0003.flac\n",
       "4  103-1240-0004.flac"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_male.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for a file that gets automatically generated and we need to drop \n",
    "df_male[df_male['file']=='.DS_Store']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the same for the female folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filelist = os.listdir('female') \n",
    "# #read them into pandas\n",
    "# df_female = pd.DataFrame(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_female['label']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_female = df_female.rename(columns={0:'file'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_female.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking for a file that gets automatically generated and we need to drop \n",
    "# df_female[df_female['file']=='.DS_Store']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the system file\n",
    "# df_female.drop(981, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index since we dropped a row\n",
    "# df_female = df_female.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining both dataframes together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([df_female, df_male], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103-1240-0000.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103-1240-0001.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103-1240-0002.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103-1240-0003.flac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103-1240-0004.flac</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file\n",
       "0  103-1240-0000.flac\n",
       "1  103-1240-0001.flac\n",
       "2  103-1240-0002.flac\n",
       "3  103-1240-0003.flac\n",
       "4  103-1240-0004.flac"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_male.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_male.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2370"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to do an split of train, validation and test with 70% train, 20% validation and 10% for test. We check that the randomized splits have balanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:1600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df[1600:1800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_validation['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[1800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to extract the features and label for each sound file by iterating through every row of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although this function was modified and many parameteres were explored with, most of it\n",
    "# came from Source 8 (sources in the READ.ME)\n",
    "\n",
    "def extract_features(files):\n",
    "    \n",
    "    # Sets the name to be the path to where the file is in my computer\n",
    "    file_name = os.path.join(os.path.abspath('source')+'/'+str(files.file))\n",
    "\n",
    "    # Loads the audio file as a floating point time series and assigns the default sample rate\n",
    "    # Sample rate is set to 22050 by default\n",
    "    X, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "\n",
    "    # Generate Mel-frequency cepstral coefficients (MFCCs) from a time series \n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "\n",
    "    # Generates a Short-time Fourier transform (STFT) to use in the chroma_stft\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "\n",
    "    # Computes a chromagram from a waveform or power spectrogram.\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes a mel-scaled spectrogram.\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes spectral contrast\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "\n",
    "    # Computes the tonal centroid features (tonnetz)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "    sr=sample_rate).T,axis=0)\n",
    "        \n",
    "    \n",
    "    # We add also the classes of each file as a label at the end\n",
    "#     label = files.label\n",
    "\n",
    "    return mfccs, chroma, mel, contrast, tonnetz #, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to start the timer to see how long it takes to extract the features\n",
    "startTime = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=831\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=795\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=946\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=865\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=986\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=783\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=934\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=686\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=853\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=814\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=929\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=838\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=991\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=824\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=927\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=841\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=760\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=755\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=805\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=707\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=845\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=803\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=857\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=791\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=712\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=784\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=938\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=752\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=957\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=1015\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=1019\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=998\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=953\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=678\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=741\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=800\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=972\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=977\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=989\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=996\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=807\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=901\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=881\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=969\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=1024 is too small for input signal of length=819\n",
      "  n_fft, y.shape[-1]\n"
     ]
    }
   ],
   "source": [
    "# Applying the function to the train data by accessing each row of the dataframe\n",
    "features_label = df.apply(extract_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:37:21.053588\n"
     ]
    }
   ],
   "source": [
    "# Code to see how long it took\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ([-358.4652, 91.62154, -54.416817, 29.428865, ...\n",
       "1       ([-337.83096, 118.637085, -43.04103, 55.654465...\n",
       "2       ([-442.1549, 123.60432, 1.0404664, 49.69681, -...\n",
       "3       ([-430.2393, 119.45682, -21.997358, 39.519283,...\n",
       "4       ([-368.61032, 123.3883, -40.216217, 54.60901, ...\n",
       "5       ([-331.19516, 99.19405, -29.1898, 51.928238, -...\n",
       "6       ([-286.22995, 94.15037, -60.42427, 67.472046, ...\n",
       "7       ([-334.2393, 118.76558, -35.435295, 51.88353, ...\n",
       "8       ([-381.3552, 101.365906, -33.492317, 54.846992...\n",
       "9       ([-233.70636, 131.73514, -22.442453, 35.748188...\n",
       "10      ([-326.0352, 133.74205, -5.9101596, 51.428097,...\n",
       "11      ([-283.60043, 95.91734, -60.80046, 69.603745, ...\n",
       "12      ([-410.60834, 138.47823, -33.196297, 31.917805...\n",
       "13      ([-323.8894, 115.3959, -52.464832, 58.539745, ...\n",
       "14      ([-368.02167, 129.70161, -28.490015, 58.119934...\n",
       "15      ([-363.85992, 113.357895, -41.577885, 27.71254...\n",
       "16      ([-344.3103, 114.602425, -42.454277, 69.62651,...\n",
       "17      ([-333.49417, 72.599754, -47.162563, 64.76349,...\n",
       "18      ([-367.37314, 114.221886, -4.5376697, 36.51296...\n",
       "19      ([-329.31036, 111.89442, -45.365078, 28.578331...\n",
       "20      ([-444.61395, 87.339905, -40.368206, 60.630352...\n",
       "21      ([-466.74326, 110.30888, 15.224068, 38.561985,...\n",
       "22      ([-300.46136, 134.97162, -32.131275, 44.397552...\n",
       "23      ([-363.03012, 99.31941, -36.44514, 61.765068, ...\n",
       "24      ([-306.118, 128.3591, -25.808859, 44.42677, -8...\n",
       "25      ([-358.28995, 120.196846, -48.069702, 65.78734...\n",
       "26      ([-392.81143, 102.92458, -21.403383, 45.8048, ...\n",
       "27      ([-330.05704, 121.05646, -38.3052, 30.88421, -...\n",
       "28      ([-366.95267, 126.40088, -6.8192344, 44.25836,...\n",
       "29      ([-223.59477, 113.57801, -21.769257, 38.273666...\n",
       "                              ...                        \n",
       "2340    ([-373.6704, 81.75412, -46.642002, 67.7944, -1...\n",
       "2341    ([-341.7913, 121.47449, -39.008232, 33.010616,...\n",
       "2342    ([-207.08017, 115.20379, -31.868126, 40.72819,...\n",
       "2343    ([-276.98477, 104.03891, -59.834846, 57.284676...\n",
       "2344    ([-392.74097, 109.777275, -32.133682, 58.39111...\n",
       "2345    ([-442.10605, 112.23362, -0.74079514, 53.49193...\n",
       "2346    ([-405.77707, 117.93002, -22.441643, 18.958477...\n",
       "2347    ([-343.11874, 94.24205, -27.135782, 56.531754,...\n",
       "2348    ([-355.1648, 115.88365, -45.348133, 66.78546, ...\n",
       "2349    ([-396.10648, 102.33778, -21.323774, 37.08884,...\n",
       "2350    ([-392.28232, 77.17234, 23.05755, 31.859503, 7...\n",
       "2351    ([-261.13785, 126.51246, -37.37721, 36.576256,...\n",
       "2352    ([-303.4279, 77.91889, -44.46697, 31.254328, -...\n",
       "2353    ([-317.05466, 137.43808, -41.58533, 33.41847, ...\n",
       "2354    ([-344.92197, 103.540085, -25.89348, 51.623634...\n",
       "2355    ([-325.41968, 91.680565, -53.8624, 61.029884, ...\n",
       "2356    ([-325.6417, 80.36763, -51.79853, 37.20587, -1...\n",
       "2357    ([-312.22644, 113.45102, -33.955883, 42.61877,...\n",
       "2358    ([-357.6942, 89.76273, -17.375778, 18.803835, ...\n",
       "2359    ([-407.63998, 115.88497, -21.496754, 33.065434...\n",
       "2360    ([-348.85602, 124.656265, -12.973094, 55.81726...\n",
       "2361    ([-473.41824, 114.85043, -20.858479, 58.10608,...\n",
       "2362    ([-279.01996, 131.63881, -47.075245, 37.249916...\n",
       "2363    ([-347.197, 100.47467, -35.89047, 61.615833, -...\n",
       "2364    ([-299.56027, 102.233116, -32.943504, 43.49699...\n",
       "2365    ([-352.69376, 120.28614, -36.283512, 63.114433...\n",
       "2366    ([-372.97525, 116.20953, -16.573195, 44.74387,...\n",
       "2367    ([-370.6145, 108.61034, -34.95661, 31.44733, -...\n",
       "2368    ([-307.87363, 143.07883, -21.337969, 48.141647...\n",
       "2369    ([-328.7999, 85.9275, -58.18303, 25.385384, -1...\n",
       "Length: 2370, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how the output looks\n",
    "features_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next code in markdown saves the numpy array (in case our kernel restarts or \n",
    "# anything happens, because it takes long to extract the features)\n",
    "\n",
    "# np.save('features_label', features_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next code loads the saved numpy array of our extracted features\n",
    "# features_label = np.load('features_label.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We create an empty list where we will concatenate all the features into one long feature\n",
    "# for each file to feed into our neural network \n",
    "\n",
    "features = []\n",
    "for i in range(0, len(features_label)):\n",
    "    features.append(np.concatenate((features_label[i][0], features_label[i][1], \n",
    "                features_label[i][2], features_label[i][3],\n",
    "                features_label[i][4]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2370"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will add the speaker id to our dataframe to have that as the label for our model and predict speakers from their voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an empty list where we will append all the speakers ids for each row of our\n",
    "# dataframe by slicing the file name since we know the id is the first numbers before the hash\n",
    "speaker = []\n",
    "for i in range(0, len(df)):\n",
    "    speaker.append(df['file'][i].split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create the speaker column in our dataframe and set it equal to our speaker list\n",
    "df['speaker'] = speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87-121553-0067.flac</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27-124992-0078.flac</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163-122947-0021.flac</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198-126831-0040.flac</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27-123349-0024.flac</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file speaker\n",
       "0   87-121553-0067.flac      87\n",
       "1   27-124992-0078.flac      27\n",
       "2  163-122947-0021.flac     163\n",
       "3  198-126831-0040.flac     198\n",
       "4   27-123349-0024.flac      27"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking that it worked as expected\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of speakers or the number of different people in our voice data\n",
    "df['speaker'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting our labels to be equal to our speaker list\n",
    "labels = speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2370"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the size of labels and making sure it matches the size of features\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking if we have balanced classes for the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['103', '118', '125', '150', '163', '19', '196', '198', '200',\n",
       "        '201', '26', '27', '32', '39', '40', '60', '78', '83', '87', '89'],\n",
       "       dtype='<U3'),\n",
       " array([102, 137, 138, 114, 112, 111, 108, 126, 116, 127, 118, 138, 117,\n",
       "        123, 114,  97, 118, 123, 108, 123], dtype=int64))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# They look somewhat balanced with a min of 56 and a max of 166, mean of 114 \n",
    "# with standard deviation of 15.89 (calculated from scipy)\n",
    "np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hot encoding y and pre processing X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hot encoding y\n",
    "lb = LabelEncoder()\n",
    "y = to_categorical(lb.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2370, 193)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2370, 20)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the first 9188 (70%) files to be our train data\n",
    "# Choosing the next  2625 (20%) files to be our validation data\n",
    "# Choosing the next  1312 (10%) files to be our test never before seen data\n",
    "# This is analogous to a train test split but we add a validation split and we are making\n",
    "# we do not shuffle anything since we are dealing with several time series, we already \n",
    "# checked before that we have balanced classes (analogous to stratify)\n",
    "\n",
    "X_train = X[:1600]\n",
    "y_train = y[:1600]\n",
    "\n",
    "X_val = X[1600:2000]\n",
    "y_val = y[1600:2000]\n",
    "\n",
    "X_test = X[2000:]\n",
    "y_test = y[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_val = ss.transform(X_val)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple dense model with early stopping with softmax for categorical classification\n",
    "# We have 115 classes \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(193, input_shape=(193,), activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.25))  \n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))    \n",
    "\n",
    "model.add(Dense(20, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/100\n",
      "1600/1600 [==============================] - ETA: 5s - loss: 3.2745 - acc: 0.046 - ETA: 1s - loss: 3.1241 - acc: 0.071 - ETA: 0s - loss: 2.9552 - acc: 0.117 - 1s 796us/sample - loss: 2.9480 - acc: 0.1200 - val_loss: 2.3957 - val_acc: 0.6175\n",
      "Epoch 2/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 2.5667 - acc: 0.273 - 0s 33us/sample - loss: 2.3432 - acc: 0.3681 - val_loss: 1.8140 - val_acc: 0.7325\n",
      "Epoch 3/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 2.0175 - acc: 0.492 - 0s 36us/sample - loss: 1.8106 - acc: 0.5319 - val_loss: 1.1453 - val_acc: 0.8400\n",
      "Epoch 4/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 1.5228 - acc: 0.636 - 0s 35us/sample - loss: 1.3232 - acc: 0.6544 - val_loss: 0.6030 - val_acc: 0.9200\n",
      "Epoch 5/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 1.0707 - acc: 0.710 - 0s 31us/sample - loss: 0.9343 - acc: 0.7400 - val_loss: 0.3124 - val_acc: 0.9475\n",
      "Epoch 6/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.7385 - acc: 0.800 - 0s 35us/sample - loss: 0.6727 - acc: 0.8150 - val_loss: 0.1754 - val_acc: 0.9725\n",
      "Epoch 7/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.5735 - acc: 0.855 - 0s 35us/sample - loss: 0.4688 - acc: 0.8850 - val_loss: 0.1092 - val_acc: 0.9775\n",
      "Epoch 8/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.4195 - acc: 0.871 - 0s 38us/sample - loss: 0.3683 - acc: 0.9019 - val_loss: 0.0742 - val_acc: 0.9900\n",
      "Epoch 9/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.3014 - acc: 0.910 - 0s 38us/sample - loss: 0.2684 - acc: 0.9300 - val_loss: 0.0540 - val_acc: 0.9900\n",
      "Epoch 10/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.2409 - acc: 0.929 - 0s 36us/sample - loss: 0.2081 - acc: 0.9475 - val_loss: 0.0413 - val_acc: 0.9950\n",
      "Epoch 11/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.2227 - acc: 0.921 - 0s 35us/sample - loss: 0.1723 - acc: 0.9581 - val_loss: 0.0333 - val_acc: 0.9950\n",
      "Epoch 12/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.1558 - acc: 0.953 - 0s 33us/sample - loss: 0.1433 - acc: 0.9650 - val_loss: 0.0285 - val_acc: 0.9950\n",
      "Epoch 13/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.1233 - acc: 0.972 - 0s 37us/sample - loss: 0.1075 - acc: 0.9731 - val_loss: 0.0274 - val_acc: 0.9925\n",
      "Epoch 14/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0896 - acc: 0.980 - 0s 43us/sample - loss: 0.0855 - acc: 0.9787 - val_loss: 0.0242 - val_acc: 0.9950\n",
      "Epoch 15/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0925 - acc: 0.972 - 0s 36us/sample - loss: 0.0945 - acc: 0.9744 - val_loss: 0.0216 - val_acc: 0.9975\n",
      "Epoch 16/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0682 - acc: 0.980 - 0s 40us/sample - loss: 0.0768 - acc: 0.9812 - val_loss: 0.0202 - val_acc: 0.9950\n",
      "Epoch 17/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.1016 - acc: 0.968 - 0s 35us/sample - loss: 0.0665 - acc: 0.9850 - val_loss: 0.0187 - val_acc: 0.9950\n",
      "Epoch 18/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.1030 - acc: 0.964 - 0s 33us/sample - loss: 0.0688 - acc: 0.9862 - val_loss: 0.0172 - val_acc: 0.9950\n",
      "Epoch 19/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0455 - acc: 0.996 - 0s 34us/sample - loss: 0.0473 - acc: 0.9900 - val_loss: 0.0162 - val_acc: 0.9950\n",
      "Epoch 20/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0319 - acc: 1.000 - 0s 34us/sample - loss: 0.0485 - acc: 0.9919 - val_loss: 0.0161 - val_acc: 0.9950\n",
      "Epoch 21/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0613 - acc: 0.988 - 0s 40us/sample - loss: 0.0465 - acc: 0.9900 - val_loss: 0.0158 - val_acc: 0.9975\n",
      "Epoch 22/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0297 - acc: 1.000 - 0s 39us/sample - loss: 0.0511 - acc: 0.9881 - val_loss: 0.0159 - val_acc: 0.9975\n",
      "Epoch 23/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0486 - acc: 0.996 - 0s 35us/sample - loss: 0.0492 - acc: 0.9906 - val_loss: 0.0172 - val_acc: 0.9975\n",
      "Epoch 24/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0363 - acc: 0.992 - 0s 34us/sample - loss: 0.0303 - acc: 0.9950 - val_loss: 0.0183 - val_acc: 0.9975\n",
      "Epoch 25/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0405 - acc: 0.996 - 0s 38us/sample - loss: 0.0342 - acc: 0.9931 - val_loss: 0.0168 - val_acc: 0.9975\n",
      "Epoch 26/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0261 - acc: 0.996 - 0s 50us/sample - loss: 0.0294 - acc: 0.9919 - val_loss: 0.0154 - val_acc: 0.9975\n",
      "Epoch 27/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0314 - acc: 0.992 - 0s 38us/sample - loss: 0.0292 - acc: 0.9919 - val_loss: 0.0132 - val_acc: 0.9975\n",
      "Epoch 28/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0283 - acc: 0.996 - 0s 33us/sample - loss: 0.0358 - acc: 0.9906 - val_loss: 0.0119 - val_acc: 0.9975\n",
      "Epoch 29/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0205 - acc: 0.996 - 0s 34us/sample - loss: 0.0316 - acc: 0.9912 - val_loss: 0.0123 - val_acc: 0.9975\n",
      "Epoch 30/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0218 - acc: 0.992 - 0s 35us/sample - loss: 0.0245 - acc: 0.9950 - val_loss: 0.0129 - val_acc: 0.9975\n",
      "Epoch 31/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0107 - acc: 1.000 - 0s 40us/sample - loss: 0.0194 - acc: 0.9981 - val_loss: 0.0133 - val_acc: 0.9975\n",
      "Epoch 32/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0194 - acc: 0.996 - 0s 40us/sample - loss: 0.0220 - acc: 0.9962 - val_loss: 0.0145 - val_acc: 0.9975\n",
      "Epoch 33/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0259 - acc: 0.992 - 0s 32us/sample - loss: 0.0223 - acc: 0.9950 - val_loss: 0.0157 - val_acc: 0.9975\n",
      "Epoch 34/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0140 - acc: 0.996 - 0s 40us/sample - loss: 0.0235 - acc: 0.9956 - val_loss: 0.0160 - val_acc: 0.9975\n",
      "Epoch 35/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0147 - acc: 1.000 - 0s 38us/sample - loss: 0.0150 - acc: 0.9981 - val_loss: 0.0169 - val_acc: 0.9950\n",
      "Epoch 36/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0255 - acc: 0.992 - 0s 35us/sample - loss: 0.0182 - acc: 0.9969 - val_loss: 0.0166 - val_acc: 0.9975\n",
      "Epoch 37/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0241 - acc: 0.996 - 0s 34us/sample - loss: 0.0160 - acc: 0.9969 - val_loss: 0.0158 - val_acc: 0.9975\n",
      "Epoch 38/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0111 - acc: 0.996 - 0s 32us/sample - loss: 0.0149 - acc: 0.9962 - val_loss: 0.0143 - val_acc: 0.9975\n",
      "Epoch 39/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0283 - acc: 0.988 - 0s 30us/sample - loss: 0.0185 - acc: 0.9956 - val_loss: 0.0127 - val_acc: 0.9975\n",
      "Epoch 40/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0168 - acc: 0.996 - 0s 28us/sample - loss: 0.0163 - acc: 0.9969 - val_loss: 0.0114 - val_acc: 0.9975\n",
      "Epoch 41/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0109 - acc: 0.996 - 0s 31us/sample - loss: 0.0113 - acc: 0.9994 - val_loss: 0.0109 - val_acc: 0.9975\n",
      "Epoch 42/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0087 - acc: 1.000 - 0s 33us/sample - loss: 0.0120 - acc: 0.9987 - val_loss: 0.0110 - val_acc: 0.9975\n",
      "Epoch 43/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0148 - acc: 0.996 - ETA: 0s - loss: 0.0135 - acc: 0.998 - 0s 48us/sample - loss: 0.0136 - acc: 0.9981 - val_loss: 0.0118 - val_acc: 0.9975\n",
      "Epoch 44/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0106 - acc: 0.996 - 0s 31us/sample - loss: 0.0137 - acc: 0.9975 - val_loss: 0.0135 - val_acc: 0.9975\n",
      "Epoch 45/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0232 - acc: 0.996 - 0s 34us/sample - loss: 0.0209 - acc: 0.9975 - val_loss: 0.0148 - val_acc: 0.9975\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0176 - acc: 0.992 - 0s 36us/sample - loss: 0.0120 - acc: 0.9969 - val_loss: 0.0159 - val_acc: 0.9975\n",
      "Epoch 47/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0042 - acc: 1.000 - 0s 36us/sample - loss: 0.0080 - acc: 0.9981 - val_loss: 0.0162 - val_acc: 0.9975\n",
      "Epoch 48/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0070 - acc: 1.000 - 0s 27us/sample - loss: 0.0109 - acc: 0.9987 - val_loss: 0.0160 - val_acc: 0.9975\n",
      "Epoch 49/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0077 - acc: 1.000 - 0s 26us/sample - loss: 0.0103 - acc: 0.9987 - val_loss: 0.0169 - val_acc: 0.9975\n",
      "Epoch 50/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0064 - acc: 1.000 - 0s 37us/sample - loss: 0.0089 - acc: 0.9987 - val_loss: 0.0173 - val_acc: 0.9975\n",
      "Epoch 51/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0126 - acc: 1.000 - 0s 30us/sample - loss: 0.0133 - acc: 0.9969 - val_loss: 0.0174 - val_acc: 0.9975\n",
      "Epoch 52/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0077 - acc: 1.000 - 0s 27us/sample - loss: 0.0114 - acc: 0.9969 - val_loss: 0.0147 - val_acc: 0.9975\n",
      "Epoch 53/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0092 - acc: 0.996 - 0s 27us/sample - loss: 0.0089 - acc: 0.9969 - val_loss: 0.0144 - val_acc: 0.9975\n",
      "Epoch 54/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0085 - acc: 0.996 - 0s 27us/sample - loss: 0.0122 - acc: 0.9969 - val_loss: 0.0158 - val_acc: 0.9975\n",
      "Epoch 55/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0085 - acc: 1.000 - 0s 27us/sample - loss: 0.0089 - acc: 0.9987 - val_loss: 0.0167 - val_acc: 0.9975\n",
      "Epoch 56/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0088 - acc: 1.000 - 0s 31us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 0.9975\n",
      "Epoch 57/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0170 - acc: 0.996 - 0s 27us/sample - loss: 0.0100 - acc: 0.9981 - val_loss: 0.0172 - val_acc: 0.9975\n",
      "Epoch 58/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0037 - acc: 1.000 - 0s 30us/sample - loss: 0.0076 - acc: 0.9981 - val_loss: 0.0162 - val_acc: 0.9975\n",
      "Epoch 59/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0100 - acc: 0.992 - ETA: 0s - loss: 0.0083 - acc: 0.995 - 0s 58us/sample - loss: 0.0082 - acc: 0.9962 - val_loss: 0.0173 - val_acc: 0.9975\n",
      "Epoch 60/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0056 - acc: 1.000 - 0s 34us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 0.9975\n",
      "Epoch 61/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0055 - acc: 1.000 - 0s 28us/sample - loss: 0.0065 - acc: 0.9987 - val_loss: 0.0199 - val_acc: 0.9975\n",
      "Epoch 62/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0050 - acc: 1.000 - 0s 26us/sample - loss: 0.0060 - acc: 0.9987 - val_loss: 0.0212 - val_acc: 0.9975\n",
      "Epoch 63/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0119 - acc: 0.996 - 0s 29us/sample - loss: 0.0052 - acc: 0.9994 - val_loss: 0.0226 - val_acc: 0.9975\n",
      "Epoch 64/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0101 - acc: 0.996 - 0s 33us/sample - loss: 0.0076 - acc: 0.9981 - val_loss: 0.0241 - val_acc: 0.9975\n",
      "Epoch 65/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0046 - acc: 1.000 - 0s 27us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 0.9975\n",
      "Epoch 66/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0034 - acc: 1.000 - ETA: 0s - loss: 0.0050 - acc: 1.000 - 0s 57us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 0.9975\n",
      "Epoch 67/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0074 - acc: 0.996 - 0s 32us/sample - loss: 0.0057 - acc: 0.9987 - val_loss: 0.0223 - val_acc: 0.9975\n",
      "Epoch 68/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0042 - acc: 1.000 - ETA: 0s - loss: 0.0061 - acc: 0.999 - 0s 65us/sample - loss: 0.0085 - acc: 0.9975 - val_loss: 0.0209 - val_acc: 0.9975\n",
      "Epoch 69/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0072 - acc: 1.000 - ETA: 0s - loss: 0.0058 - acc: 0.999 - 0s 56us/sample - loss: 0.0063 - acc: 0.9994 - val_loss: 0.0204 - val_acc: 0.9975\n",
      "Epoch 70/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0032 - acc: 1.000 - ETA: 0s - loss: 0.0043 - acc: 1.000 - 0s 52us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 0.9975\n",
      "Epoch 71/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0024 - acc: 1.000 - 0s 37us/sample - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0187 - val_acc: 0.9975\n",
      "Epoch 72/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0050 - acc: 1.000 - 0s 44us/sample - loss: 0.0092 - acc: 0.9987 - val_loss: 0.0199 - val_acc: 0.9975\n",
      "Epoch 73/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0064 - acc: 0.996 - 0s 38us/sample - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0206 - val_acc: 0.9975\n",
      "Epoch 74/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0167 - acc: 0.992 - ETA: 0s - loss: 0.0071 - acc: 0.998 - 0s 84us/sample - loss: 0.0059 - acc: 0.9987 - val_loss: 0.0217 - val_acc: 0.9975\n",
      "Epoch 75/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.000 - 0s 29us/sample - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0209 - val_acc: 0.9975\n",
      "Epoch 76/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0068 - acc: 1.000 - 0s 29us/sample - loss: 0.0069 - acc: 0.9987 - val_loss: 0.0202 - val_acc: 0.9975\n",
      "Epoch 77/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0061 - acc: 0.996 - 0s 38us/sample - loss: 0.0042 - acc: 0.9994 - val_loss: 0.0200 - val_acc: 0.9975\n",
      "Epoch 78/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0042 - acc: 1.000 - 0s 29us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 0.9975\n",
      "Epoch 79/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0024 - acc: 1.000 - 0s 29us/sample - loss: 0.0053 - acc: 0.9994 - val_loss: 0.0195 - val_acc: 0.9975\n",
      "Epoch 80/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0108 - acc: 0.992 - 0s 29us/sample - loss: 0.0073 - acc: 0.9975 - val_loss: 0.0188 - val_acc: 0.9975\n",
      "Epoch 81/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 9.6296e-04 - acc: 1.000 - 0s 33us/sample - loss: 0.0042 - acc: 0.9994 - val_loss: 0.0184 - val_acc: 0.9975\n",
      "Epoch 82/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.000 - 0s 30us/sample - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 0.9975\n",
      "Epoch 83/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0037 - acc: 1.000 - 0s 31us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 0.9975\n",
      "Epoch 84/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0035 - acc: 1.000 - 0s 33us/sample - loss: 0.0049 - acc: 0.9994 - val_loss: 0.0193 - val_acc: 0.9975\n",
      "Epoch 85/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.000 - 0s 38us/sample - loss: 0.0035 - acc: 0.9994 - val_loss: 0.0189 - val_acc: 0.9975\n",
      "Epoch 86/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.000 - 0s 33us/sample - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 0.9975\n",
      "Epoch 87/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0036 - acc: 1.000 - 0s 30us/sample - loss: 0.0060 - acc: 0.9975 - val_loss: 0.0189 - val_acc: 0.9975\n",
      "Epoch 88/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0034 - acc: 1.000 - 0s 36us/sample - loss: 0.0054 - acc: 0.9994 - val_loss: 0.0185 - val_acc: 0.9975\n",
      "Epoch 89/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0047 - acc: 0.996 - 0s 64us/sample - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0178 - val_acc: 0.9975\n",
      "Epoch 90/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0030 - acc: 1.000 - 0s 30us/sample - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0174 - val_acc: 0.9975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0044 - acc: 0.996 - 0s 28us/sample - loss: 0.0055 - acc: 0.9981 - val_loss: 0.0170 - val_acc: 0.9975\n",
      "Epoch 92/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.000 - 0s 26us/sample - loss: 0.0035 - acc: 0.9987 - val_loss: 0.0173 - val_acc: 0.9975\n",
      "Epoch 93/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0032 - acc: 1.000 - 0s 27us/sample - loss: 0.0052 - acc: 0.9981 - val_loss: 0.0174 - val_acc: 0.9975\n",
      "Epoch 94/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0034 - acc: 1.000 - 0s 30us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 0.9975\n",
      "Epoch 95/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0025 - acc: 1.000 - 0s 36us/sample - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 0.9975\n",
      "Epoch 96/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0024 - acc: 1.000 - 0s 35us/sample - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 0.9975\n",
      "Epoch 97/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0036 - acc: 1.000 - 0s 28us/sample - loss: 0.0041 - acc: 0.9987 - val_loss: 0.0195 - val_acc: 0.9975\n",
      "Epoch 98/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.000 - 0s 28us/sample - loss: 0.0064 - acc: 0.9981 - val_loss: 0.0198 - val_acc: 0.9975\n",
      "Epoch 99/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.000 - 0s 32us/sample - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 0.9975\n",
      "Epoch 100/100\n",
      "1600/1600 [==============================] - ETA: 0s - loss: 0.0017 - acc: 1.000 - 0s 28us/sample - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0205 - val_acc: 0.9975\n"
     ]
    }
   ],
   "source": [
    "# fitting the model with the train data and validation with the validation data\n",
    "# we used early stop with patience 100 because we did not want to use early stop\n",
    "# I leave the early stop regularization code in case anyone wants to use it\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=256, epochs=100, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stop])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history.history[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out our train accuracy and validation accuracy over epochs.\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "train_accuracy = history.history['acc']\n",
    "val_accuracy = history.history['val_acc']\n",
    "\n",
    "# Set figure size.\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Generate line plot of training, testing loss over epochs.\n",
    "plt.plot(train_accuracy, label='Training Accuracy', color='#185fad')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy', color='orange')\n",
    "\n",
    "# Set title\n",
    "plt.title('Training and Validation Accuracy by Epoch', fontsize = 25)\n",
    "plt.xlabel('Epoch', fontsize = 18)\n",
    "plt.ylabel('Categorical Crossentropy', fontsize = 18)\n",
    "plt.xticks(range(0,100,5), range(0,100,5))\n",
    "\n",
    "plt.legend(fontsize = 18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get our predictions from the test data\n",
    "preds = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We transform back our predictions to the speakers ids\n",
    "preds = lb.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We slice our dataframe to our test dataframe\n",
    "df_test = df[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\syed\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# We create a new column called preds and set it equal to our predictions\n",
    "df_test['preds'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>speaker</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>89-218-0051.flac</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>118-47824-0013.flac</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>39-121916-0005.flac</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>27-124992-0019.flac</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>125-121124-0013.flac</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>26-496-0022.flac</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>87-121553-0083.flac</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>150-132655-0005.flac</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>78-368-0033.flac</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>118-47824-0082.flac</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>19-227-0036.flac</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>19-227-0001.flac</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>27-124992-0046.flac</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>27-123349-0026.flac</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>118-124588-0001.flac</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>19-198-0011.flac</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>78-369-0031.flac</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>27-124992-0061.flac</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>163-122947-0050.flac</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>163-122947-0095.flac</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>39-121916-0023.flac</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>19-227-0023.flac</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>201-127786-0022.flac</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>40-222-0066.flac</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>32-4137-0054.flac</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>163-122947-0054.flac</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>27-124992-0023.flac</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>150-126112-0024.flac</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>200-126784-0031.flac</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>125-121124-0063.flac</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>125-121124-0068.flac</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>40-222-0063.flac</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>198-129977-0027.flac</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>32-21625-0010.flac</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>39-121915-0003.flac</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>163-122947-0031.flac</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>83-11691-0030.flac</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>198-209-0001.flac</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>27-124992-0006.flac</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>40-121026-0041.flac</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>163-122947-0058.flac</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>198-129977-0004.flac</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>87-121553-0040.flac</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>40-222-0004.flac</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "      <td>196-122152-0018.flac</td>\n",
       "      <td>196</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>125-121124-0030.flac</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>87-121553-0048.flac</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>196-122150-0025.flac</td>\n",
       "      <td>196</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>83-11691-0014.flac</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>60-121082-0066.flac</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>118-47824-0056.flac</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>200-126784-0017.flac</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>19-227-0072.flac</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2363</th>\n",
       "      <td>39-121916-0015.flac</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>39-121914-0034.flac</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>201-122255-0025.flac</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>78-368-0038.flac</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>83-9960-0001.flac</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>201-127786-0041.flac</td>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>87-121553-0036.flac</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      file speaker preds\n",
       "2000      89-218-0051.flac      89    89\n",
       "2001   118-47824-0013.flac     118   118\n",
       "2002   39-121916-0005.flac      39    39\n",
       "2003   27-124992-0019.flac      27    27\n",
       "2004  125-121124-0013.flac     125   125\n",
       "2005      26-496-0022.flac      26    26\n",
       "2006   87-121553-0083.flac      87    87\n",
       "2007  150-132655-0005.flac     150   150\n",
       "2008      78-368-0033.flac      78    78\n",
       "2009   118-47824-0082.flac     118   118\n",
       "2010      19-227-0036.flac      19    19\n",
       "2011      19-227-0001.flac      19    19\n",
       "2012   27-124992-0046.flac      27    27\n",
       "2013   27-123349-0026.flac      27    27\n",
       "2014  118-124588-0001.flac     118   118\n",
       "2015      19-198-0011.flac      19    19\n",
       "2016      78-369-0031.flac      78    78\n",
       "2017   27-124992-0061.flac      27    27\n",
       "2018  163-122947-0050.flac     163   163\n",
       "2019  163-122947-0095.flac     163   163\n",
       "2020   39-121916-0023.flac      39    39\n",
       "2021      19-227-0023.flac      19    19\n",
       "2022  201-127786-0022.flac     201   201\n",
       "2023      40-222-0066.flac      40    40\n",
       "2024     32-4137-0054.flac      32    32\n",
       "2025  163-122947-0054.flac     163   163\n",
       "2026   27-124992-0023.flac      27    27\n",
       "2027  150-126112-0024.flac     150   150\n",
       "2028  200-126784-0031.flac     200   200\n",
       "2029  125-121124-0063.flac     125   125\n",
       "...                    ...     ...   ...\n",
       "2340  125-121124-0068.flac     125   125\n",
       "2341      40-222-0063.flac      40    40\n",
       "2342  198-129977-0027.flac     198   198\n",
       "2343    32-21625-0010.flac      32    32\n",
       "2344   39-121915-0003.flac      39    39\n",
       "2345  163-122947-0031.flac     163   163\n",
       "2346    83-11691-0030.flac      83    83\n",
       "2347     198-209-0001.flac     198   198\n",
       "2348   27-124992-0006.flac      27    27\n",
       "2349   40-121026-0041.flac      40    40\n",
       "2350  163-122947-0058.flac     163   163\n",
       "2351  198-129977-0004.flac     198   198\n",
       "2352   87-121553-0040.flac      87    87\n",
       "2353      40-222-0004.flac      40    40\n",
       "2354  196-122152-0018.flac     196   196\n",
       "2355  125-121124-0030.flac     125   125\n",
       "2356   87-121553-0048.flac      87    87\n",
       "2357  196-122150-0025.flac     196   196\n",
       "2358    83-11691-0014.flac      83    83\n",
       "2359   60-121082-0066.flac      60    60\n",
       "2360   118-47824-0056.flac     118   118\n",
       "2361  200-126784-0017.flac     200   200\n",
       "2362      19-227-0072.flac      19    19\n",
       "2363   39-121916-0015.flac      39    39\n",
       "2364   39-121914-0034.flac      39    39\n",
       "2365  201-122255-0025.flac     201   201\n",
       "2366      78-368-0038.flac      78    78\n",
       "2367     83-9960-0001.flac      83    83\n",
       "2368  201-127786-0041.flac     201   201\n",
       "2369   87-121553-0036.flac      87    87\n",
       "\n",
       "[370 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how our test dataframe looks like now with our predictions\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>speaker</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file, speaker, preds]\n",
       "Index: []"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many speakers we got wrong\n",
    "df_test[df_test['speaker'] != df_test['preds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking our model accuracy\n",
    "1-round(len(df_test[df_test['speaker'] != df_test['preds']])/len(df_test),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 99.8% accurate on test data for classification of speakers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
